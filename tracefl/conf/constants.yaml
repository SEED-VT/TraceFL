parallel_processes: 0 # parallelizing provenance
client_weights_normalization: False # provenance

check_train_cache: true # if set to True then if the config is already in the cache then it will not retrain.
check_prov_cache: false
check_dataset_cache: True


dataset_channels:
    cifar10: 3 # RGB
    mnist: 3
    pathmnist: 3
    organamnist: 3
    superb: None
    dbpedia_14: None
    yahoo_answers_topics: None

dataset_classes:
    cifar10: 10
    mnist: 10
    pathmnist: 9
    organamnist: 11
    yahoo_answers_topics: 10 # Text
    dbpedia_14: 14 # Text

model_arch:
    distilbert/distilbert-base-uncased: transformer
    openai-community/openai-gpt: transformer
    google-bert/bert-base-cased: transformer
    resnet18: cnn
    densenet121: cnn

storage:
    dir: storage_of_exps/
    train_cache_name: cache_of_training
    results_cache_name: cache_of_approach
    fl_datasets_cache: cache_of_fl_datasets
    fed_debug_cache_name: cache_of_fed_debug_results

# fed_debug config
multirun_faulty_clients: -1 # use for hydra multirun to pass clients ids to `faulty_clients_ids` as we cannot pass list of  list in multirun
noise_rate: None
faulty_clients_ids: [] # malacious client(s) ids in a list
label2flip: None
neuron_activation_threshold: 0.003
faster_input_generation: True

